{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Feature Engineering Assignment**"
      ],
      "metadata": {
        "id": "4fGsByAbvpIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What is a parameter?\n",
        "\n",
        "In the context of machine learning, a parameter is a variable that the model learns during training. These are the internal configuration variables that determine how the model makes predictions. For example, in linear regression, the coefficients and intercept are parameters that the model adjusts to best fit the data.\n",
        "\n",
        "                                                  or\n",
        "\n",
        "In Machine Learning, a **parameter** is something the model learns from the training data. For example, in a line equation like `y = mx + c`, `m` and `c` are parameters. The model tries to find the best values of these to make accurate predictions.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. What is correlation?\n",
        "\n",
        "Correlation is a statistical measure that expresses the extent to which two variables are linearly related. It measures both the strength and direction of the relationship between two variables. Correlation values range from -1 to +1, where:\n",
        "\n",
        "- +1 indicates a perfect positive correlation\n",
        "- 0 indicates no correlation\n",
        "-1 indicates a perfect negative correlation\n",
        "---\n",
        "\n",
        "## 3. What does negative correlation mean?\n",
        "\n",
        "Negative correlation means that as one variable increases, the other variable tends to decrease. For example, if there's a negative correlation between study hours and exam failure rate, it means that as study hours increase, the failure rate tends to decrease. Graphically, points in a scatter plot would form a pattern from the upper left to the lower right.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Define Machine Learning. What are the main components?\n",
        "\n",
        "Machine Learning is a subset of artificial intelligence that enables computers to learn from data and improve from experience without being explicitly programmed. The machine \"learns\" patterns from data and makes predictions or decisions based on what it has learned.\n",
        "\n",
        "Main components of Machine Learning:\n",
        "\n",
        "1. Data: The information used to train the model\n",
        "2. Features: The variables or attributes in the data\n",
        "3.Algorithm: The mathematical approach used for learning patterns\n",
        "4.Model: The representation learned from the data\n",
        "5.Training: The process of learning patterns from data\n",
        "6.Evaluation: Assessing how well the model performs\n",
        "Hyperparameters: Configuration settings for the algorithm\n",
        "\n",
        "---\n",
        "\n",
        "## 5. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "The loss value measures how far the model's predictions are from the actual values. A lower loss value indicates better performance. When training a model, we aim to minimize this loss value.\n",
        "\n",
        "The loss value helps determine if a model is good by:\n",
        "\n",
        "- Tracking improvement during training\n",
        "- Comparing different models\n",
        "- Identifying overfitting (when training loss decreases but validation loss increases)\n",
        "- Setting a benchmark for acceptable performance\n",
        "\n",
        "A good model will have a low loss value on both training and testing data.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables:\n",
        "\n",
        "- Can take any numerical value within a range\n",
        "- Examples: height, weight, temperature, income\n",
        "- Can be measured on a scale and can have decimal values\n",
        "\n",
        "Categorical variables:\n",
        "\n",
        "- Take on discrete values representing categories or groups\n",
        "- Examples: gender, country, color, yes/no responses\n",
        "- Cannot be meaningfully ordered or used in calculations\n",
        "\n",
        "---\n",
        "\n",
        "## 7.How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "\n",
        "Common techniques for handling categorical variables:\n",
        "\n",
        "###1. Label Encoding:\n",
        "\n",
        "- Converts each category to a unique integer\n",
        "- Suitable for ordinal categories (where order matters)"
      ],
      "metadata": {
        "id": "LyMAvkl8v6ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a sample dataset\n",
        "data = pd.DataFrame({\n",
        "    'category': ['apple', 'banana', 'apple', 'orange', 'banana', 'orange', 'apple']\n",
        "})\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'category' column\n",
        "data['category_encoded'] = encoder.fit_transform(data['category'])\n",
        "\n",
        "# Show the original and encoded data\n",
        "print(data)\n",
        "\n",
        "# Optional: Display the mapping of labels\n",
        "label_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "print(\"\\nLabel Mapping:\")\n",
        "print(label_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvmYJU0L9ccM",
        "outputId": "d0b58827-fbce-4e3f-b7ad-905acac832e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  category  category_encoded\n",
            "0    apple                 0\n",
            "1   banana                 1\n",
            "2    apple                 0\n",
            "3   orange                 2\n",
            "4   banana                 1\n",
            "5   orange                 2\n",
            "6    apple                 0\n",
            "\n",
            "Label Mapping:\n",
            "{'apple': np.int64(0), 'banana': np.int64(1), 'orange': np.int64(2)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. One-Hot Encoding:\n",
        "\n",
        "- Creates binary columns for each category\n",
        "- Avoids implying ordinal relationships"
      ],
      "metadata": {
        "id": "L6oZJWXT92Ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "encoded_data = pd.get_dummies(data, columns=['category'])\n",
        "encoded_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "XVIwVjDh-bMK",
        "outputId": "538cfd52-cd07-4df0-e215-dd18ccfb343c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   category_encoded  category_apple  category_banana  category_orange\n",
              "0                 0            True            False            False\n",
              "1                 1           False             True            False\n",
              "2                 0            True            False            False\n",
              "3                 2           False            False             True\n",
              "4                 1           False             True            False\n",
              "5                 2           False            False             True\n",
              "6                 0            True            False            False"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d43b6505-c158-4ac5-bf81-8369cac99631\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category_encoded</th>\n",
              "      <th>category_apple</th>\n",
              "      <th>category_banana</th>\n",
              "      <th>category_orange</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d43b6505-c158-4ac5-bf81-8369cac99631')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d43b6505-c158-4ac5-bf81-8369cac99631 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d43b6505-c158-4ac5-bf81-8369cac99631');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c3cb0d63-e8a5-4a76-87a5-2dc6e8b3e0a9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3cb0d63-e8a5-4a76-87a5-2dc6e8b3e0a9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c3cb0d63-e8a5-4a76-87a5-2dc6e8b3e0a9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_dc7fb35f-dc47-481c-8838-4110602cf864\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('encoded_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dc7fb35f-dc47-481c-8838-4110602cf864 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('encoded_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "encoded_data",
              "summary": "{\n  \"name\": \"encoded_data\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"category_encoded\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_apple\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_banana\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_orange\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Binary Encoding:\n",
        "\n",
        "- Represents categories as binary code\n",
        "- More memory-efficient than one-hot for many categories\n",
        "\n",
        "###4. Target Encoding:\n",
        "\n",
        "- Replaces categories with the mean target value for that category\n",
        "- Useful for high-cardinality features\n",
        "\n",
        "###5. Frequency Encoding:\n",
        "\n",
        "Replaces categories with their frequency in the dataset\n",
        "\n",
        "---\n",
        "\n",
        "## 8. What is training and testing a dataset?\n",
        "\n",
        "**Training a dataset**:\n",
        "\n",
        "- Using a portion of the data to teach the model patterns and relationships\n",
        "- The model learns from this data by adjusting its parameters\n",
        "- The goal is for the model to learn general patterns, not memorize the data\n",
        "\n",
        "**Testing a dataset**:\n",
        "\n",
        "- Using a separate portion of data (unseen during training) to evaluate model performance\n",
        "- Tests the model's ability to generalize to new, unseen data\n",
        "- Provides an unbiased evaluation of the model's performance\n",
        "\n",
        "This split helps prevent overfitting and gives a more realistic estimate of how the model will perform in real-world scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. What is `sklearn.preprocessing`?\n",
        "\n",
        "sklearn.preprocessing is a module in the Scikit-learn library that provides functions and classes for data preprocessing. These tools help transform raw data into a format that is more suitable for machine learning algorithms.\n",
        "\n",
        "Key features include:\n",
        "\n",
        "- Scaling: StandardScaler, MinMaxScaler, RobustScaler\n",
        "- Normalization: Normalizer\n",
        "- Encoding: OneHotEncoder, LabelEncoder\n",
        "- Transformation: PolynomialFeatures, PowerTransformer\n",
        "- Imputation: SimpleImputer (for handling missing values)\n",
        "\n",
        "Example:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0aphS9YH9HT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling using StandardScaler\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Sample dataset\n",
        "data = pd.DataFrame({\n",
        "    'height': [160, 170, 180, 190],\n",
        "    'weight': [55, 65, 75, 85],\n",
        "    'age': [20, 25, 30, 35]\n",
        "})\n",
        "\n",
        "# Display original data\n",
        "print(\"Original Data:\")\n",
        "print(data)\n",
        "\n",
        "# Apply Standard Scaling (mean = 0, std = 1)\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Convert back to DataFrame for better readability\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
        "\n",
        "print(\"\\nScaled Data (StandardScaler):\")\n",
        "print(scaled_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P9RJ5X5Bcg7",
        "outputId": "028f846b-a2dc-43da-9040-46cb58ff6153"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "   height  weight  age\n",
            "0     160      55   20\n",
            "1     170      65   25\n",
            "2     180      75   30\n",
            "3     190      85   35\n",
            "\n",
            "Scaled Data (StandardScaler):\n",
            "     height    weight       age\n",
            "0 -1.341641 -1.341641 -1.341641\n",
            "1 -0.447214 -0.447214 -0.447214\n",
            "2  0.447214  0.447214  0.447214\n",
            "3  1.341641  1.341641  1.341641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. What is a Test set?\n",
        "\n",
        "A test set is a portion of the original dataset that is set aside and not used during the training process. It represents new, unseen data that the model will encounter in real-world applications.\n",
        "\n",
        "The test set serves several important purposes:\n",
        "\n",
        "- Evaluates how well the model generalizes to new data\n",
        "- Provides an unbiased evaluation of the final model's performance\n",
        "- Helps detect overfitting (if the model performs significantly worse on test data)\n",
        "- Simulates real-world deployment scenarios\n",
        "\n",
        "A good test set should be representative of the overall data distribution and large enough to provide statistically significant results.\n",
        "\n",
        "---\n",
        "\n",
        "## 11. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "We use the `train_test_split()` function from **scikit-learn** to split our dataset into two parts:\n",
        "- One part for **training the model**\n",
        "- Another part for **testing how well the model performs**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x0r9sWTEBauG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split with model training and prediction\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 1: Create a sample dataset\n",
        "data = pd.DataFrame({\n",
        "    'experience': [1, 2, 3, 4, 5, 6, 7, 8],\n",
        "    'salary': [30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000]\n",
        "})\n",
        "\n",
        "# Step 2: Define features (X) and target (y)\n",
        "X = data[['experience']]\n",
        "y = data['salary']\n",
        "\n",
        "# Step 3: Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,       # 20% test set\n",
        "    random_state=42      # Reproducible results\n",
        ")\n",
        "\n",
        "# Step 4: Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Predict on test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluate the model\n",
        "print(\"Predictions:\", predictions)\n",
        "print(\"Actual:\", y_test.values)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, predictions))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej0PfKBhCwao",
        "outputId": "0244deb4-65cb-4d2e-d6ff-c77558349503"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [35000. 55000.]\n",
            "Actual: [35000 55000]\n",
            "Mean Squared Error: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test_size parameter controls what proportion goes to the test set (typically 20-30%).\n",
        "The random_state parameter ensures reproducibility by using the same random split each time.\n",
        "\n",
        "For time series data or when random splitting isn't appropriate, other methods like TimeSeriesSplit can be used.\n",
        "\n",
        "---\n",
        "\n",
        "## 12. How do you approach a ML problem?\n",
        "\n",
        "A systematic approach to a machine learning problem:\n",
        "\n",
        "1.Problem Definition\n",
        "\n",
        "- Clearly define the problem and objectives\n",
        "- Identify what success looks like\n",
        "- Determine appropriate evaluation metrics\n",
        "\n",
        "2.Data Collection\n",
        "\n",
        "- Gather relevant data from various sources\n",
        "- Ensure data quality and quantity\n",
        "\n",
        "3.Exploratory Data Analysis (EDA)\n",
        "\n",
        "- Understand data distributions and relationships\n",
        "- Identify patterns, outliers, and missing values\n",
        "- Visualize key insights\n",
        "\n",
        "4.Data Preprocessing\n",
        "\n",
        "- Handle missing values\n",
        "- Convert categorical variables\n",
        "- Scale/normalize features\n",
        "- Create new features if needed\n",
        "\n",
        "5.Feature Selection/Engineering\n",
        "\n",
        "- Select relevant features\n",
        "- Create new features to improve model performance\n",
        "- Reduce dimensionality if necessary\n",
        "\n",
        "6.Model Selection\n",
        "\n",
        "- Choose appropriate algorithms based on the problem\n",
        "- Consider interpretability vs. performance trade-offs\n",
        "\n",
        "7.Training and Validation\n",
        "\n",
        "- Split data into training, validation, and test sets\n",
        "- Train multiple models\n",
        "- Use cross-validation for robust evaluation\n",
        "\n",
        "8.Hyperparameter Tuning\n",
        "\n",
        "- Optimize model parameters\n",
        "- Use grid search or random search\n",
        "\n",
        "9.Model Evaluation\n",
        "\n",
        "- Assess performance on test data\n",
        "- Analyze errors and edge cases\n",
        "\n",
        "10.Deployment and Monitoring\n",
        "\n",
        "- Implement the model in production\n",
        "- Monitor performance over time\n",
        "- Retrain as needed\n",
        "\n",
        "---\n",
        "\n",
        "## 13. Why do EDA before fitting a model?\n",
        "\n",
        "Exploratory Data Analysis (EDA) is crucial before model fitting because:\n",
        "\n",
        "1. Understanding the Data: EDA helps you understand the structure, patterns, and characteristics of your data. This understanding guides feature selection and engineering.\n",
        "\n",
        "2. Identifying Issues: EDA reveals missing values, outliers, imbalanced classes, or skewed distributions that could negatively impact model performance.\n",
        "\n",
        "3. Feature Relationships: EDA uncovers relationships between features and the target variable, helping identify which features might be most important.\n",
        "\n",
        "4. Data Quality Assessment: EDA helps detect data quality issues like duplicate records, inconsistent formats, or data entry errors.\n",
        "\n",
        "5. Informing Preprocessing: EDA guides decisions about scaling, transformation, encoding, and other preprocessing steps.\n",
        "\n",
        "6. Hypothesis Generation: EDA helps generate hypotheses about what factors influence the target variable.\n",
        "\n",
        "7. Preventing Surprises: EDA helps avoid unexpected issues during model training that could waste time and computational resources.\n",
        "\n",
        "8. Guiding Model Selection: Understanding data characteristics helps choose appropriate models (e.g., linear vs. non-linear).\n",
        "\n",
        "By performing thorough EDA, you set a strong foundation for successful modeling and avoid potential pitfalls.\n",
        "\n",
        "---\n",
        "## 14. What is correlation?\n",
        "\n",
        "Correlation is a statistical measure that indicates the extent to which two variables change together. It measures both the strength and direction of the linear relationship between two variables.\n",
        "\n",
        "Key points about correlation:\n",
        "\n",
        "- It ranges from -1 to +1\n",
        "- A value close to +1 indicates a strong positive relationship\n",
        "- A value close to -1 indicates a strong negative relationship\n",
        "- A value near 0 indicates little or no linear relationship\n",
        "\n",
        "The most common measure is the Pearson correlation coefficient, which specifically measures linear relationships. Other types include Spearman's rank correlation (for non-linear monotonic relationships) and Kendall's tau.\n",
        "\n",
        "ðŸ“Œ **Example**:  \n",
        "When temperature increases, ice cream sales also increase â€” this is **positive correlation**.\n",
        "\n",
        "---\n",
        "\n",
        "## 15. What does negative correlation mean?\n",
        "\n",
        "**Negative correlation** means that when one value increases, the other one decreases.  \n",
        "They move in **opposite directions**.\n",
        "\n",
        "ðŸ“Œ **Example**:  \n",
        "As the number of hours you spend watching TV goes up, your exam score might go down.  \n",
        "This is a **negative correlation**.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 16. How can you find correlation between variables in Python?\n",
        "\n",
        "In Python, there are several ways to find correlations between variables:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load sample data\n",
        "df = pd.DataFrame({\n",
        "    'feature1': np.random.normal(0, 1, 100),\n",
        "    'feature2': np.random.normal(0, 1, 100),\n",
        "    'feature3': np.random.normal(0, 1, 100)\n",
        "})\n",
        "\n",
        "# Create a correlated feature\n",
        "df['feature4'] = df['feature1'] * 2 + np.random.normal(0, 0.5, 100)\n",
        "\n",
        "# Method 1: Correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Method 2: Visual representation with heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Method 3: Pairplot to visualize relationships\n",
        "sns.pairplot(df)\n",
        "plt.show()\n",
        "\n",
        "# Method 4: Calculate specific correlation\n",
        "specific_corr = df['feature1'].corr(df['feature4'])\n",
        "print(f\"Correlation between feature1 and feature4: {specific_corr:.2f}\")\n",
        "\n",
        "```\n",
        "\n",
        "For non-linear relationships,\n",
        "\n",
        "```python\n",
        "spearman_corr = df.corr(method='spearman')\n",
        "print(spearman_corr)\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 17. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "Causation refers to a relationship where one event (the cause) directly influences another event (the effect). It implies that a change in one variable directly causes a change in another variable.\n",
        "\n",
        "Difference between correlation and causation:\n",
        "\n",
        "1. Correlation: Measures how variables change together; doesn't imply that one causes the other\n",
        "2. Causation: Indicates that changes in one variable directly cause changes in another\n",
        "\n",
        "Example:\n",
        "\n",
        "Ice cream sales â†‘ and drowning cases â†‘ = correlated\n",
        "But eating ice cream doesn't cause drowning = no causation\n",
        "There is a strong positive correlation between ice cream sales and drowning deaths. Both increase during summer months.\n",
        "\n",
        "- Correlation perspective: Ice cream sales and drowning deaths are positively correlated.\n",
        "- Causation reality: Ice cream sales don't cause drownings, nor do drownings cause ice cream sales.\n",
        "- Actual explanation: The hidden variable is hot weather/summer season, which independently causes both increased ice cream consumption and more people swimming (leading to more drowning incidents).\n",
        "\n",
        "This example demonstrates why \"correlation does not imply causation\" is a fundamental principle in data analysis. To establish causation, you typically need controlled experiments or more sophisticated causal inference techniques.\n",
        "\n",
        "---\n",
        "\n",
        "## 18. What is an Optimizer?\n",
        "\n",
        "An **optimizer** helps the model improve by reducing the loss value. It adjusts model parameters step by step.\n",
        "\n",
        "Types:\n",
        "- **SGD (Stochastic Gradient Descent)**\n",
        "- **Adam**\n",
        "- **RMSprop**\n",
        "\n",
        "Example in Keras:\n",
        "```python\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 19. What is `sklearn.linear_model`?\n",
        "\n",
        "Itâ€™s a module in scikit-learn that has models for linear regression, logistic regression, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## 20. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "The model.fit() method trains a machine learning model on the provided data. It's where the model learns from the data by adjusting its parameters to minimize the loss function.\n",
        "\n",
        "Required arguments:\n",
        "\n",
        "- X: The feature data (independent variables), typically a 2D array or DataFrame\n",
        "- y: The target data (dependent variable), typically a 1D array or Series\n",
        "\n",
        "example:\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Create sample data\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([2, 4, 6, 8, 10])\n",
        "\n",
        "# Initialize the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Now the model has learned the parameters\n",
        "print(f\"Coefficient: {model.coef_}\")\n",
        "print(f\"Intercept: {model.intercept_}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "##21. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "The model.predict() method uses a trained machine learning model to make predictions on new data. It applies the patterns learned during training to generate output for unseen data.\n",
        "\n",
        "Required arguments:\n",
        "\n",
        "X: The feature data for which you want predictions, in the same format as the training data\n",
        "\n",
        "example:\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Create and train a model\n",
        "X_train = np.array([[1], [2], [3], [4]])\n",
        "y_train = np.array([2, 4, 6, 8])\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on new data\n",
        "X_new = np.array([[5], [6]])\n",
        "predictions = model.predict(X_new)\n",
        "print(f\"Predictions: {predictions}\")  # Should output [10, 12]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 22. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables:\n",
        "\n",
        "- Can take any numerical value within a range\n",
        "- Represent measurements where the difference between values is meaningful\n",
        "- Examples: height, weight, temperature, income, age\n",
        "- Can be further divided into interval and ratio variables\n",
        "\n",
        "Categorical variables:\n",
        "\n",
        "- Take on discrete values that represent categories or groups\n",
        "- Examples: gender, blood type, country, product category\n",
        "- Can be further divided into:\n",
        "  - Nominal: Categories with no natural order (e.g., colors, blood types)\n",
        " - Ordinal: Categories with a meaningful order (e.g., education level, satisfaction ratings)\n",
        "\n",
        "In machine learning, different handling techniques are required for these variable types because most algorithms expect numerical inputs.\n",
        "\n",
        "---\n",
        "\n",
        "## 23. What is feature scaling? How does it help in Machine Learning?\n",
        "\n",
        "Feature scaling is the process of normalizing the range of independent variables to a common scale, typically 0 to 1 or -1 to 1.\n",
        "\n",
        "How feature scaling helps in Machine Learning:\n",
        "\n",
        "1. Improves convergence speed: Algorithms like gradient descent converge faster with scaled features.\n",
        "\n",
        "2. Prevents dominance of large-scale features: Ensures that features with larger values don't dominate those with smaller values.\n",
        "\n",
        "3. Essential for distance-based algorithms: Algorithms like k-NN, k-means, and SVM that use distance calculations require scaling for proper functioning.\n",
        "\n",
        "4. Improves regularization effectiveness: L1/L2 regularization works more effectively when features are on similar scales.\n",
        "\n",
        "5. Necessary for PCA and neural networks: These methods are highly sensitive to feature scaling.\n",
        "\n",
        "Common scaling techniques include Min-Max Scaling (to 0-1 range) and Standardization (mean=0, std=1).\n",
        "\n",
        "---\n",
        "\n",
        "## 24. How to perform scaling in Python?\n",
        "In Python, we can perform feature scaling using the scikit-learn library. Here are the most common scaling methods:\n",
        "\n",
        "Using `StandardScaler` or `MinMaxScaler` from sklearn:\n",
        "\n",
        "1.StandardScaler(Standardisation):\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({\n",
        "    'height': [165, 170, 180, 190],\n",
        "    'weight': [60, 70, 80, 90],\n",
        "    'age': [20, 30, 40, 50]\n",
        "})\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Convert back to DataFrame for better viewing\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
        "print(scaled_df)\n",
        "```\n",
        "2.MinMaxScaler (Normalization):\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform the data\n",
        "normalized_data = min_max_scaler.fit_transform(data)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "normalized_df = pd.DataFrame(normalized_data, columns=data.columns)\n",
        "print(normalized_df)\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 25. What is sklearn.preprocessing?\n",
        "\n",
        "sklearn.preprocessing is a module in the scikit-learn library that provides various functions and classes for data preprocessing before machine learning model training. It helps in transforming raw data into a format suitable for ML algorithms.\n",
        "\n",
        "---\n",
        "\n",
        "## 26. How do we split data for model fitting (training and testing) in Python?\n",
        "In Python, we typically use the train_test_split function from scikit-learn to split data into training and testing sets:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create sample dataset\n",
        "np.random.seed(42)  # for reproducibility\n",
        "data = pd.DataFrame({\n",
        "    'feature1': np.random.normal(0, 1, 1000),\n",
        "    'feature2': np.random.normal(0, 1, 1000),\n",
        "    'feature3': np.random.normal(0, 1, 1000)\n",
        "})\n",
        "target = np.random.randint(0, 2, 1000)  # Binary target\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data,  # Features\n",
        "    target,  # Target variable\n",
        "    test_size=0.2,  # Use 20% for testing, 80% for training\n",
        "    random_state=42,  # For reproducible results\n",
        "    stratify=target  # Maintain same class distribution in train and test sets\n",
        ")\n",
        "\n",
        "# Check the split sizes\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Now we can train a model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# And evaluate on the test set\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(f\"Model accuracy: {accuracy:.2f}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 27. What is data encoding?\n",
        "\n",
        "Data encoding is the process of converting categorical variables (non-numeric) into a numerical format that machine learning algorithms can understand. Since most ML algorithms require numerical input, encoding is a critical preprocessing step.\n",
        "\n",
        "Common data encoding techniques:\n",
        "\n",
        "1.Label Encoding:\n",
        "\n",
        "- Assigns a unique integer to each category\n",
        "- Maintains a single column\n",
        "- Implies an ordinal relationship between categories\n",
        "- Best used when categories have a natural order\n",
        "\n",
        "Example:\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({'color': ['red', 'blue', 'green', 'red', 'blue']})\n",
        "\n",
        "# Apply label encoding\n",
        "encoder = LabelEncoder()\n",
        "data['color_encoded'] = encoder.fit_transform(data['color'])\n",
        "\n",
        "print(data)\n",
        "print(f\"Categories mapping: {dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))}\")\n",
        "```\n",
        "2.One-Hot Encoding:\n",
        "\n",
        "- Creates binary columns for each category\n",
        "- No implied ordering between categories\n",
        "- Increases dimensionality (more columns)\n",
        "- Best for nominal categorical variables\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({'color': ['red', 'blue', 'green', 'red', 'blue']})\n",
        "\n",
        "# Method 1: Using OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded = encoder.fit_transform(data[['color']])\n",
        "encoded_df = pd.DataFrame(\n",
        "    encoded,\n",
        "    columns=encoder.get_feature_names_out(['color'])\n",
        ")\n",
        "print(encoded_df)\n",
        "\n",
        "# Method 2: Using pandas get_dummies\n",
        "dummies = pd.get_dummies(data['color'], prefix='color')\n",
        "print(dummies)\n",
        "```\n",
        "3.Binary Encoding:\n",
        "\n",
        "- Represents categories as binary digits\n",
        "- More memory-efficient than one-hot for high-cardinality features\n",
        "- Middle ground between label and one-hot encoding\n",
        "\n",
        "```python\n",
        "from category_encoders import BinaryEncoder\n",
        "\n",
        "# Sample data\n",
        "data = pd.DataFrame({'color': ['red', 'blue', 'green', 'yellow', 'purple']})\n",
        "\n",
        "# Apply binary encoding\n",
        "encoder = BinaryEncoder(cols=['color'])\n",
        "binary_encoded = encoder.fit_transform(data)\n",
        "\n",
        "print(binary_encoded)\n",
        "```\n",
        "\n",
        "4.Target Encoding:\n",
        "\n",
        "- Replaces categories with the mean target value for that category\n",
        "- Useful for high-cardinality features\n",
        "- Can lead to overfitting if not carefully implemented\n",
        "\n",
        "```python\n",
        "# Manual implementation of target encoding\n",
        "data = pd.DataFrame({\n",
        "    'category': ['A', 'B', 'A', 'C', 'B', 'A', 'C'],\n",
        "    'target': [1, 0, 1, 0, 1, 1, 0]\n",
        "})\n",
        "\n",
        "# Calculate mean target value per category\n",
        "target_means = data.groupby('category')['target'].mean()\n",
        "\n",
        "# Apply encoding\n",
        "data['category_encoded'] = data['category'].map(target_means)\n",
        "\n",
        "print(data)\n",
        "```\n",
        "\n",
        "5.Ordinal Encoding:\n",
        "\n",
        "- Assigns integers based on the order of categories\n",
        "- Used when categories have a meaningful order\n",
        "\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "# Sample data with ordered categories\n",
        "data = pd.DataFrame({'size': ['small', 'medium', 'large', 'medium', 'small']})\n",
        "\n",
        "# Define the ordering\n",
        "size_ordering = [['small', 'medium', 'large']]\n",
        "\n",
        "# Apply ordinal encoding\n",
        "encoder = OrdinalEncoder(categories=size_ordering)\n",
        "data['size_encoded'] = encoder.fit_transform(data[['size']])\n",
        "\n",
        "print(data)\n",
        "```\n",
        "Choosing the right encoding method depends on the nature of the categorical variable and the specific requirements of the machine learning algorithm you're using.\n"
      ],
      "metadata": {
        "id": "G_HUp6Qg9HMh"
      }
    }
  ]
}